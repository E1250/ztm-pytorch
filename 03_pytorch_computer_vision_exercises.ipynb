{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/E1250/ztm-pytorch/blob/main/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "6328cd5b-fb68-4a72-b33e-d955a199b054"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul 26 14:58:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "8a0e8cd2-6c97-42da-f3c0-67c706f3646b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?\n",
        "1. Smartphone\n",
        "2. Modern cars\n",
        "3. Security Cameras"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find.\n",
        "\n",
        "Overfitting is a problem in machine learning that occurs when a model learns the training data too well and as a result, does not generalize well to new data. This means that the model is able to make accurate predictions on the training data, but it is not able to make accurate predictions on new data that it has not seen before."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those.\n",
        "* Using regularization. Regularization can help to prevent overfitting by adding a penalty to the model's cost function that discourages the model from becoming too complex.\n",
        "* Ensembling. Ensembling is a technique that can help to prevent overfitting by combining the predictions of multiple models. This can help to reduce the variance of the predictions, which can make the model less likely to overfit.\n",
        "* Early stopping. Early stopping is a technique that can help to prevent overfitting by stopping the training process before the model has had a chance to overfit the data.\n"
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download  = True,\n",
        "    transform = ToTensor(),\n",
        "    target_transform = None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "SHjeuN81bHza",
        "outputId": "c408ae6b-d4c8-4a37-84dc-8e960e83926f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 129714130.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 5537682.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4422102/4422102 [00:00<00:00, 68094221.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 894423.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image ,label = random.choice(train_data)\n",
        "label"
      ],
      "metadata": {
        "id": "1jaQvWoIwV33",
        "outputId": "37a78225-7027-42b8-d613-c3285cb12de0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "n = 5\n",
        "fig , ax = plt.subplots(1,5)\n",
        "for i in range(n):\n",
        "  image ,label = random.choice(train_data)\n",
        "  ax[i].imshow(image.squeeze())\n",
        "  ax[i].set_title(label)"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "outputId": "70da7997-3cd3-40c8-b93e-a98f3d57f4d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE=32\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional neural network\n",
        "from torch import nn\n",
        "\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2)\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS",
        "outputId": "68037f9d-6b63-4412-d216-2774c8cc9be4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV2(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(train_data.classes)).to('cpu')\n",
        "model_2"
      ],
      "metadata": {
        "id": "PDiZDRFmym7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqQ4mIKiywLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(train_data.classes)).to('cuda')\n",
        "model_2"
      ],
      "metadata": {
        "id": "OucBQ86vyecr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    train_loss = 0\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        model_2.train()\n",
        "        # 1. Forward pass\n",
        "        y_pred = model_2(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulatively add up the loss per epoch\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    ### Testing\n",
        "    # Setup variables for accumulatively adding up loss and accuracy\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_2.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_dataloader:\n",
        "            # 1. Forward pass\n",
        "            test_pred = model_2(X)\n",
        "\n",
        "            # 2. Calculate loss (accumatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(test_dataloader)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "# Calculate training time\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model_0.parameters()).device))"
      ],
      "metadata": {
        "id": "KjrR-TD3yuPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(size=(1,3,64,64))\n",
        "layer = nn.Conv2D"
      ],
      "metadata": {
        "id": "leCTsqtSbR5P",
        "outputId": "13bd1de2-434f-46e2-b820-bcbc4efb157c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}